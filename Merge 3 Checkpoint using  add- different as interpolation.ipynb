{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjw8Z6DCqzMtYr+z17LREy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jBBCY0xLS0O8"},"outputs":[],"source":["import os\n","import torch\n","from safetensors.torch import load_file, save_file\n","from tqdm import tqdm\n","import gc\n","\n","def get_component_type(key):\n","    \"\"\"Determine which component a key belongs to\"\"\"\n","    if key.startswith('model.diffusion_model'):\n","        return 'UNET'\n","    elif key.startswith('first_stage_model'):\n","        return 'VAE'\n","    elif key.startswith('transformer_'):\n","        return 'TEXT_ENCODER'\n","    else:\n","        return 'OTHER'\n","\n","def merge_tensors(tensor_a, tensor_b, tensor_c, alpha, beta, component_type):\n","    \"\"\"Merge tensors with component-specific logic\"\"\"\n","    if component_type == 'VAE':\n","        # Keep VAE from model A unchanged\n","        return tensor_a\n","    elif component_type == 'TEXT_ENCODER':\n","        # Keep text encoder from model A unchanged\n","        return tensor_a\n","    else:\n","        # For UNET and other components, use weighted average\n","        # This is a more conservative approach that ensures weights stay in a valid range\n","        weighted_b = (1 - alpha) * tensor_a + alpha * tensor_b\n","        weighted_c = (1 - beta) * tensor_a + beta * tensor_c\n","\n","        # Take the weighted average of the results\n","        merged = 0.5 * (weighted_b + weighted_c)\n","\n","        # Ensure the weights don't deviate too far from the original scale\n","        scale_factor = torch.mean(torch.abs(tensor_a)) / torch.mean(torch.abs(merged))\n","        merged = merged * scale_factor\n","\n","        return merged\n","\n","def save_incrementally(merged_model, path):\n","    \"\"\"Save merged tensors incrementally to avoid memory overload\"\"\"\n","    if os.path.exists(path):\n","        existing_model = load_file(path)\n","        merged_model.update(existing_model)\n","    save_file(merged_model, path)\n","    merged_model.clear()\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","# Paths to models\n","checkpoint_dir = \"/content/stable-diffusion-webui-reForge/models/Stable-diffusion\"\n","model_a_path = os.path.join(checkpoint_dir, \"waiNSFWIllustrious_v80.safetensors\")\n","model_b_path = os.path.join(checkpoint_dir, \"hassakuXLIllustrious_v12Style.safetensors\")\n","model_c_path = os.path.join(checkpoint_dir, \"illustriousXL_smoothftSOLID.safetensors\")\n","output_path = os.path.join(checkpoint_dir, \"merged_model.safetensors\")\n","\n","# Use more conservative merge parameters\n","alpha = 0.36\n","beta = 0.25\n","\n","# Validate model paths\n","print(\"Validating model paths...\")\n","for path in [model_a_path, model_b_path, model_c_path]:\n","    if not os.path.exists(path):\n","        raise FileNotFoundError(f\"Model not found at {path}\")\n","\n","# Load models\n","print(\"Loading models...\")\n","torch.cuda.empty_cache()\n","model_a = load_file(model_a_path)\n","\n","torch.cuda.empty_cache()\n","model_b = load_file(model_b_path)\n","\n","torch.cuda.empty_cache()\n","model_c = load_file(model_c_path)\n","\n","print(f\"Model statistics:\")\n","print(f\"Model A: {len(model_a.keys())} keys\")\n","print(f\"Model B: {len(model_b.keys())} keys\")\n","print(f\"Model C: {len(model_c.keys())} keys\")\n","\n","# Component tracking\n","component_counts = {'UNET': 0, 'VAE': 0, 'TEXT_ENCODER': 0, 'OTHER': 0}\n","\n","# Gather all unique keys\n","all_keys = set(model_a.keys())\n","\n","# Merge process\n","print(\"Merging models incrementally...\")\n","merged_model = {}\n","for key in tqdm(all_keys, desc=\"Merging keys\"):\n","    # Skip if key doesn't exist in model A\n","    if key not in model_a:\n","        continue\n","\n","    tensor_a = model_a[key]\n","    tensor_b = model_b.get(key, torch.zeros_like(tensor_a))\n","    tensor_c = model_c.get(key, torch.zeros_like(tensor_a))\n","\n","    # Determine component type\n","    component_type = get_component_type(key)\n","    component_counts[component_type] += 1\n","\n","    # Merge with component-specific logic\n","    merged_tensor = merge_tensors(tensor_a, tensor_b, tensor_c, alpha, beta, component_type)\n","    merged_model[key] = merged_tensor.half()\n","\n","    # Save incrementally\n","    if len(merged_model) >= 1000:\n","        save_incrementally(merged_model, output_path)\n","\n","# Save any remaining tensors\n","if merged_model:\n","    save_incrementally(merged_model, output_path)\n","\n","print(\"\\nMerge statistics by component:\")\n","for component, count in component_counts.items():\n","    print(f\"{component}: {count} keys processed\")\n","\n","print(f\"\\nMerged model saved at {output_path}\")\n","\n","# Load and check final model\n","print(\"\\nValidating merged model...\")\n","merged_model = load_file(output_path)\n","print(f\"Final merged model contains {len(merged_model.keys())} keys\")"]}]}