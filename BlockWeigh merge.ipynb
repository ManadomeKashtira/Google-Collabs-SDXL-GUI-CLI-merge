{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNbsSUFq+LwdQZGL6gxPSiA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Merging SDXL checkpoint via Layer block weight**"],"metadata":{"id":"4WW9tTEXojz3"}},{"cell_type":"markdown","source":["**Tips When merging models:**\n","\n","Lower IN blocks (00-03): Affect basic features, textures, and patterns\n","Middle IN blocks (04-06): Affect object parts and compositions\n","Higher IN blocks (07-08): Affect scene-level features\n","Middle block (M00): Affects overall style and composition\n","Higher OUT blocks (06-08): Affect major compositional elements\n","Middle OUT blocks (03-05): Affect object details and relationships\n","Lower OUT blocks (00-02): Affect final details and refinements\n","\n","Tips for adjustment:\n","\n","For style transfer: Focus on middle blocks and higher input blocks\n","For detail preservation: Adjust lower output blocks\n","For composition: Focus on middle block and higher output blocks\n","For base features: Adjust lower input blocks**"],"metadata":{"id":"R4-UwLYuQXjB"}},{"cell_type":"code","source":["import os\n","import torch\n","from safetensors.torch import load_file, save_file\n","from tqdm import tqdm\n","import gc\n","\n","# Configuration for block weights\n","# Modify these values to adjust the merge weights for different components\n","BLOCK_WEIGHTS = {\n","    # Input blocks (early layers)\n","    'input_blocks.0': 0.0, # Initial layer, processes basic image features like edges and colors\n","    'input_blocks.1': 0.0, # Low-level feature extraction\n","    'input_blocks.2': 0.0, # Basic shapes and patterns\n","    'input_blocks.3': 0.0, # Texture details\n","    'input_blocks.4': 0.0, # Simple object parts\n","    'input_blocks.5': 0.0, # More complex object parts\n","    'input_blocks.6': 0.0, # Basic object compositions\n","    'input_blocks.7': 0.0, # Object relationships\n","    'input_blocks.8': 0.0, # Higher-level scene features\n","    'input_blocks.9': 0.0,\n","    'input_blocks.10': 0.0,\n","    'input_blocks.11': 0.0,\n","\n","    # Middle blocks\n","    'middle_block': 0.5, #Middle Block (M00) This is the bottleneck layer that processes the most abstract representations Handles global context and relationships between elements Very important for overall image composition and style\n","\n","    # Output blocks (later layers)\n","    'output_blocks.0': 0.0, #Final image details and cleanup\n","    'output_blocks.1': 0.0, # Color refinement\n","    'output_blocks.2': 0.0, # Fine details\n","    'output_blocks.3': 0.0, # Texture refinement\n","    'output_blocks.4': 0.0, # Object refinement\n","    'output_blocks.5': 0.0, # Complex object details\n","    'output_blocks.6': 0.0, # Object relationships and positioning\n","    'output_blocks.7': 0.0, # Highest level abstract features\n","    'output_blocks.8': 0.0, # Complex scene composition\n","    'output_blocks.9': 0.0,\n","    'output_blocks.10': 0.0,\n","    'output_blocks.11': 0.0,\n","\n","    # Other components\n","    'time_embed': 0.5,\n","    'label_emb': 0.5,\n","    'model.diffusion': 0.5,\n","\n","    # Keep these from base model\n","    'first_stage_model': 0.0,  # VAE\n","    'transformer_': 0.0,       # Text Encoder\n","}\n","\n","def get_component_type(key):\n","    \"\"\"Determine which component a key belongs to\"\"\"\n","    if key.startswith('model.diffusion_model'):\n","        return 'UNET'\n","    elif key.startswith('first_stage_model'):\n","        return 'VAE'\n","    elif key.startswith('transformer_'):\n","        return 'TEXT_ENCODER'\n","    else:\n","        return 'OTHER'\n","\n","def get_block_weight(key):\n","    \"\"\"Get the weight for a specific key based on its block\"\"\"\n","    # Default weight if no specific match\n","    default_weight = 0.5\n","\n","    # Check for exact matches first\n","    for block_key, weight in BLOCK_WEIGHTS.items():\n","        if block_key in key:\n","            return weight\n","\n","    # Component-based fallbacks\n","    component = get_component_type(key)\n","    if component == 'VAE':\n","        return BLOCK_WEIGHTS['first_stage_model']\n","    elif component == 'TEXT_ENCODER':\n","        return BLOCK_WEIGHTS['transformer_']\n","\n","    return default_weight\n","\n","def merge_tensors(tensor_a, tensor_b, tensor_c, key):\n","    \"\"\"Merge tensors with block-specific weights\"\"\"\n","    weight = get_block_weight(key)\n","\n","    # If weight is 0, keep tensor_a unchanged\n","    if weight == 0:\n","        return tensor_a\n","\n","    # Perform weighted merge\n","    merged = (1 - weight) * tensor_a + (weight * 0.6) * tensor_b + (weight * 0.4) * tensor_c\n","\n","    # Ensure the weights don't deviate too far from the original scale\n","    scale_factor = torch.mean(torch.abs(tensor_a)) / torch.mean(torch.abs(merged))\n","    merged = merged * scale_factor\n","\n","    return merged\n","\n","def save_incrementally(merged_model, path):\n","    \"\"\"Save merged tensors incrementally to avoid memory overload\"\"\"\n","    if os.path.exists(path):\n","        existing_model = load_file(path)\n","        merged_model.update(existing_model)\n","    save_file(merged_model, path)\n","    merged_model.clear()\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","def merge_models(model_a_path, model_b_path, model_c_path, output_path):\n","    \"\"\"Main function to merge three models\"\"\"\n","    # Validate model paths\n","    print(\"Validating model paths...\")\n","    for path in [model_a_path, model_b_path, model_c_path]:\n","        if not os.path.exists(path):\n","            raise FileNotFoundError(f\"Model not found at {path}\")\n","\n","    # Load models\n","    print(\"Loading models...\")\n","    torch.cuda.empty_cache()\n","    model_a = load_file(model_a_path)\n","\n","    torch.cuda.empty_cache()\n","    model_b = load_file(model_b_path)\n","\n","    torch.cuda.empty_cache()\n","    model_c = load_file(model_c_path)\n","\n","    print(f\"Model statistics:\")\n","    print(f\"Model A: {len(model_a.keys())} keys\")\n","    print(f\"Model B: {len(model_b.keys())} keys\")\n","    print(f\"Model C: {len(model_c.keys())} keys\")\n","\n","    # Component tracking\n","    component_counts = {'UNET': 0, 'VAE': 0, 'TEXT_ENCODER': 0, 'OTHER': 0}\n","\n","    # Gather all unique keys\n","    all_keys = set(model_a.keys())\n","\n","    # Merge process\n","    print(\"Merging models incrementally...\")\n","    merged_model = {}\n","    for key in tqdm(all_keys, desc=\"Merging keys\"):\n","        # Skip if key doesn't exist in model A\n","        if key not in model_a:\n","            continue\n","\n","        tensor_a = model_a[key]\n","        tensor_b = model_b.get(key, torch.zeros_like(tensor_a))\n","        tensor_c = model_c.get(key, torch.zeros_like(tensor_a))\n","\n","        # Determine component type for tracking\n","        component_type = get_component_type(key)\n","        component_counts[component_type] += 1\n","\n","        # Merge with block-specific weights\n","        merged_tensor = merge_tensors(tensor_a, tensor_b, tensor_c, key)\n","        merged_model[key] = merged_tensor.half()\n","\n","        # Save incrementally\n","        if len(merged_model) >= 1000:\n","            save_incrementally(merged_model, output_path)\n","\n","    # Save any remaining tensors\n","    if merged_model:\n","        save_incrementally(merged_model, output_path)\n","\n","    print(\"\\nMerge statistics by component:\")\n","    for component, count in component_counts.items():\n","        print(f\"{component}: {count} keys processed\")\n","\n","    print(f\"\\nMerged model saved at {output_path}\")\n","\n","    # Load and check final model\n","    print(\"\\nValidating merged model...\")\n","    merged_model = load_file(output_path)\n","    print(f\"Final merged model contains {len(merged_model.keys())} keys\")\n","\n","if __name__ == \"__main__\":\n","    # Paths to models\n","    checkpoint_dir = \"/content/stable-diffusion-webui/models/Stable-diffusion\"\n","    model_a_path = os.path.join(checkpoint_dir, \"modelA.safetensors\")\n","    model_b_path = os.path.join(checkpoint_dir, \"modelB.safetensors\")\n","    model_c_path = os.path.join(checkpoint_dir, \"modelC.safetensors\")\n","    output_path = os.path.join(checkpoint_dir, \"merged_block_weighted.safetensors\")\n","\n","    merge_models(model_a_path, model_b_path, model_c_path, output_path)"],"metadata":{"id":"s6XpKGNepbzO"},"execution_count":null,"outputs":[]}]}